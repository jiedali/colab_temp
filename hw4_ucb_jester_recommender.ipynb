{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw4_ucb_jester_recommender.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmZ4nMwqUpPCWvMBYp6Uix",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiedali/colab_temp/blob/main/hw4_ucb_jester_recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGh7EgyUBFZl",
        "outputId": "deb867eb-845b-4708-fb35-84c6c5de3b40"
      },
      "source": [
        "import numpy as np\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYyB1mzFBGiE"
      },
      "source": [
        "def sample_jester_data(file_name='/content/gdrive/MyDrive/jester_data_40jokes_19181users.npy', context_dim = 32, num_actions = 8, num_contexts = 19181,\n",
        "    shuffle_rows=True, shuffle_cols=False):\n",
        "    \"\"\"Samples bandit game from (user, joke) dense subset of Jester dataset.\n",
        "    Args:\n",
        "       file_name: Route of file containing the modified Jester dataset.\n",
        "       context_dim: Context dimension (i.e. vector with some ratings from a user).\n",
        "       num_actions: Number of actions (number of joke ratings to predict).\n",
        "       num_contexts: Number of contexts to sample.\n",
        "       shuffle_rows: If True, rows from original dataset are shuffled.\n",
        "       shuffle_cols: Whether or not context/action jokes are randomly shuffled.\n",
        "    Returns:\n",
        "       dataset: Sampled matrix with rows: (context, rating_1, ..., rating_k).\n",
        "       opt_vals: Vector of deterministic optimal (reward, action) for each context.\n",
        "\"\"\"\n",
        "    np.random.seed(0)\n",
        "    with tf.gfile.Open(file_name, 'rb') as f:\n",
        "       dataset = np.load(f)\n",
        "    if shuffle_cols:\n",
        "       dataset = dataset[:, np.random.permutation(dataset.shape[1])]\n",
        "    if shuffle_rows:\n",
        "       np.random.shuffle(dataset)\n",
        "    dataset = dataset[:num_contexts, :]\n",
        "    assert context_dim + num_actions == dataset.shape[1], 'Wrong data dimensions.'\n",
        "  \n",
        "\n",
        "    opt_actions = np.argmax(dataset[:, context_dim:], axis=1)\n",
        "    opt_rewards = np.array([dataset[i, context_dim + a] for i, a in enumerate(opt_actions)])\n",
        "    \n",
        "    return dataset, opt_rewards, opt_actions"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izBQcye1BU43"
      },
      "source": [
        "# Note: opt_rewards is based only on the last 8 jokes, from which we are trying to recommed\n",
        "dataset, opt_rewards, opt_actions=sample_jester_data()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa6HzyWGBYRw",
        "outputId": "9c98feaa-5c11-481b-e4a1-a0baf1501ee4"
      },
      "source": [
        "dataset.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19181, 40)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0rFzy_uBZZo",
        "outputId": "46967b73-dbda-4e21-dcd3-5d80172b1829"
      },
      "source": [
        "opt_rewards.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19181,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zb4u_MhBasa",
        "outputId": "934dac34-e770-4797-b9a4-fb400221f1d3"
      },
      "source": [
        "opt_actions.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19181,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot7s42UqAiCG"
      },
      "source": [
        "## First fit linear regression, get theta[arm, feature]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxB7DtvzBgUx"
      },
      "source": [
        "# fit linear regression model and get theta\n",
        "from sklearn.linear_model import LinearRegression\n",
        "# initialize an numpy array to store theta\n",
        "theta = np.zeros((8,32))\n",
        "\n",
        "# fit linear regression for each of the last 8 jokes (8 arms)\n",
        "# assemble the training data for each of the arm\n",
        "for arm in range(0,8):\n",
        "  # choose the training data with only the target \"arm\" being pulled\n",
        "  train_data = dataset[opt_actions==arm, 0:32]\n",
        "  # the labels for each arm is different\n",
        "  train_label = dataset[opt_actions==arm,32+arm]\n",
        "  # fit linear regressio for each specific arm\n",
        "  reg = LinearRegression().fit(train_data, train_label)\n",
        "  # get theta for each arm\n",
        "  theta[arm,:] = reg.coef_"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OCze8N8Tgu1",
        "outputId": "83b36c8d-207b-4ade-95ea-f87307fd57cb"
      },
      "source": [
        "theta.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v4zLyP5BJt1"
      },
      "source": [
        "## Define the function to run UCB algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if6A3SPBI4Wx"
      },
      "source": [
        "def ucb_choose_arm(person):\n",
        "  # for all 8 possible arms\n",
        "  p=np.empty([8,])\n",
        "  for a in range(0,8):\n",
        "    # compute UCB choice of arm for each person\n",
        "    x_i = dataset[opt_actions==arm,0:32]\n",
        "    A = np.matmul(x_i.transpose(), x_i)\n",
        "    A_inverse = np.linalg.inv(A)\n",
        "    #\n",
        "    feature_vec = dataset[person,0:32]\n",
        "    # this will be a single number, reward variance for arm a for one person\n",
        "    response_variance = feature_vec.dot(A_inverse).dot(feature_vec)\n",
        "    #\n",
        "    a_upper_ci = alpha * np.sqrt(response_variance)\n",
        "    a_mean = theta[arm,:].dot(feature_vec)\n",
        "    #\n",
        "    p[a] = a_mean + a_upper_ci\n",
        "  \n",
        "  # randomely break tie\n",
        "  p = p + (np.random.random(len(p))*0.00000001)\n",
        "  action_chosen = p.argmax()\n",
        "  reward_chosen = dataset[person,32+p.argmax()]\n",
        "  # update the rewards from that choice, just look up\n",
        "  # print(\"debug: choice is\")\n",
        "  # print(p.argmax())\n",
        "  # ucb_choice_reward.append(dataset[person,32+p.argmax()])\n",
        "\n",
        "  return action_chosen, reward_chosen"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uir0IvFzzLY5"
      },
      "source": [
        "## Tuning hyperparameter alpha"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wR7XvM7D3ZD"
      },
      "source": [
        "# now perform action based UCB and compute the regret\n",
        "# regret will be computed for the remaining 19181-18000 = 1181 persons\n",
        "# we will plot regret vs hyperparameter C, to get the best C value\n",
        "regret_list=[]\n",
        "alpha_list=[]\n",
        "for alpha in [0.2, 0.5, 0.8, 1, 2, 5, 10, 100, 200, 500, 1000]:\n",
        "# for alpha in [0.2]:\n",
        "  alpha_list.append(alpha)\n",
        "  true_ideal_reward=[]\n",
        "  choices=[]\n",
        "  ucb_choice_reward=[]\n",
        "  person_cnt =0\n",
        "  regret_each_person=[]\n",
        "  # for person in range(18000,18001):\n",
        "  for person in range(18000,19181):\n",
        "    # for each person, we know which joke is his favorite based on his rating\n",
        "    # we will also figure out an action based on the 8 linear regression model we got\n",
        "    # basically. according to UCB algorithm, we get a choice\n",
        "    # then we compute the delta between the ratings of his favourite and the rating of UCB choice\n",
        "    # record the array of all the True ideal reward\n",
        "    # record the array of the UBC choice reward\n",
        "    # get the regret for all persons, that's the regret for a given hyperparameter C\n",
        "\n",
        "    # True favourite joke's reward\n",
        "    true_ideal_reward.append(opt_rewards[person])\n",
        "    # figure out an arm to pull based on UCB\n",
        "    # the following function will just update choices array with the action chosen by UCB\n",
        "    action_chosen, reward_chosen = ucb_choose_arm(person)\n",
        "    #\n",
        "    person_cnt +=1\n",
        "    # compute regret for the specific person\n",
        "    regret_each_person.append(opt_rewards[person]-reward_chosen)\n",
        "\n",
        "  regret_each_person_np = np.array(regret_each_person)\n",
        "  # compute the average regret of each person\n",
        "  average_regret_all_person = np.sum(regret_each_person_np)/person_cnt\n",
        "  # save the average regret for the chosen alpha\n",
        "  regret_list.append(average_regret_all_person)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIM5hP-3D1P3",
        "outputId": "a74c70d3-11f9-4102-8eaa-cba6a716614c"
      },
      "source": [
        "alpha_list"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2, 0.5, 0.8, 1, 2, 5, 10, 100, 200, 500, 1000]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifTKeV2oEznV",
        "outputId": "5de230c8-3485-4280-bcaa-e475b7dd5959"
      },
      "source": [
        "regret_list"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.935850973751059,\n",
              " 4.892320067739204,\n",
              " 4.725139712108383,\n",
              " 5.008509737510584,\n",
              " 4.909432684165961,\n",
              " 4.796731583403895,\n",
              " 4.91623200677392,\n",
              " 4.837933954276037,\n",
              " 5.022303132938188,\n",
              " 4.871778154106689,\n",
              " 4.877679932260796]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "UJ1CoBn8Do9f",
        "outputId": "af6d88ec-e962-47d0-d7f8-e608b136caae"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.scatter(alpha_list,regret_list)\n",
        "plt.title(\"Average regret across all persons, vs Hyperparameter alpha\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Average regret across all persons, vs Hyperparameter alpha')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0ZJsck2E46s"
      },
      "source": [
        "## Experiment shows alpha = 0.8 gives the lowest regret"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUhAa3ltzg2S"
      },
      "source": [
        "## Plot regret for people in the test data using alpha=0.8: \n",
        "## Number of persons: 19181-18000=1181"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSgYey2rFPUv"
      },
      "source": [
        "# now perform action based UCB and compute the regret\n",
        "# regret will be computed for the remaining 19181-18000 = 1181 persons\n",
        "# we will plot regret vs hyperparameter C, to get the best C value\n",
        "for alpha in [0.8]:\n",
        "  true_ideal_reward=[]\n",
        "  choices=[]\n",
        "  ucb_choice_reward=[]\n",
        "  person_cnt =0\n",
        "  regret_each_person=[]\n",
        "  # for person in range(18000,18001):\n",
        "  for person in range(18000,19181):\n",
        "    # for each person, we know which joke is his favorite based on his rating\n",
        "    # we will also figure out an action based on the 8 linear regression model we got\n",
        "    # basically. according to UCB algorithm, we get a choice\n",
        "    # then we compute the delta between the ratings of his favourite and the rating of UCB choice\n",
        "    # record the array of all the True ideal reward\n",
        "    # record the array of the UBC choice reward\n",
        "    # get the regret for all persons, that's the regret for a given hyperparameter C\n",
        "\n",
        "    # True favourite joke's reward\n",
        "    true_ideal_reward.append(opt_rewards[person])\n",
        "    # figure out an arm to pull based on UCB\n",
        "    # the following function will just update choices array with the action chosen by UCB\n",
        "    action_chosen, reward_chosen = ucb_choose_arm(person)\n",
        "    #\n",
        "    person_cnt +=1\n",
        "    # compute regret for the specific person\n",
        "    regret_each_person.append(opt_rewards[person]-reward_chosen)\n",
        "\n",
        "  regret_each_person_np = np.array(regret_each_person)\n",
        "  # compute the average regret of each person\n",
        "  average_regret_all_person = np.sum(regret_each_person_np)/person_cnt\n",
        "  # save the average regret for the chosen alpha\n",
        "  regret_list.append(average_regret_all_person)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "I0bUzwI4zRgo",
        "outputId": "2cb0e1fe-d17e-4651-ba9c-1d003d01da74"
      },
      "source": [
        "# now perform action based UCB and compute the regret\n",
        "# regret will be computed for the remaining 19181-18000 = 1181 persons\n",
        "# we will plot regret vs hyperparameter C, to get the best C value\n",
        "for alpha in [0.8]:\n",
        "  true_ideal_reward=[]\n",
        "  choices=[]\n",
        "  ucb_choice_reward=[]\n",
        "  person_cnt =0\n",
        "  # for person in range(18000,18001):\n",
        "  for person in range(18000,19181):\n",
        "    # for each person, we know which joke is his favorite based on his rating\n",
        "    # we will also figure out an action based on the 8 linear regression model we got\n",
        "    # basically. according to UCB algorithm, we get a choice\n",
        "    # then we compute the delta between the ratings of his favourite and the rating of UCB choice\n",
        "    # record the array of all the True ideal reward\n",
        "    # record the array of the UBC choice reward\n",
        "    # get the regret for all persons, that's the regret for a given hyperparameter C\n",
        "\n",
        "    # True favourite joke's reward\n",
        "    true_ideal_reward.append(opt_rewards[person])\n",
        "    # figure out an arm to pull based on UCB\n",
        "    # the following function will just update choices array with the action chosen by UCB\n",
        "    ucb_choose_arm(person)\n",
        "    person_cnt +=1\n",
        "    # \n",
        "    # mean_ideal_reward = np.sum(true_ideal_reward)/(1)\n",
        "    # mean_ucb_reward = np.sum(ucb_choice_reward)/(1)\n",
        "  #\n",
        "  # mean_ideal_reward = np.sum(true_ideal_reward)\n",
        "  # mean_ucb_reward = np.sum(ucb_choice_reward)\n",
        "  #\n",
        "  true_ideal_reward_np = np.array(true_ideal_reward)\n",
        "  ucb_choice_reward_np =np.array(ucb_choice_reward)\n",
        "  regret = np.subtract(true_ideal_reward_np,ucb_choice_reward_np)\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-100b2d23c844>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m   \u001b[0mtrue_ideal_reward_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_ideal_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m   \u001b[0mucb_choice_reward_np\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mucb_choice_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mregret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_ideal_reward_np\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mucb_choice_reward_np\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1181,) (0,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gF5veuSD01jn"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure()\n",
        "plt.plot(range(regret.shape[0]), regret)\n",
        "plt.savefig('/content/gdrive/MyDrive/rl_hw4_regret_for_each_person.png')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpEXuCykxzik"
      },
      "source": [
        "regret_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZxlr-zRxRLn"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De_yNTAItxia"
      },
      "source": [
        "plt.plot()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}